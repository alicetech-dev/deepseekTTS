# deepseekTTS: Conversaci칩n por Voz con DeepSeek en Local y en la Nube

Este repositorio contiene dos scripts para interactuar con el modelo de lenguaje DeepSeek de forma innovadora:

1. **deepseek_tts_chat.sh (Debian Local):** Un script de bash para sistemas Debian que te permite tener una conversaci칩n interactiva con DeepSeek utilizando tu micr칩fono y sintetizando las respuestas a voz mediante la API de Kokoro TTS.
2. **Ollama_Ngrok_Colab.ipynb (Google Colab):** Un cuaderno de Google Colab para ejecutar Ollama (y por ende, modelos como DeepSeek) en la nube, y hacerlo accesible de forma remota a trav칠s de un t칰nel seguro de Ngrok.

## 1. deepseek_tts_chat.sh: Chatea con DeepSeek por Voz en Debian

Este script te permite tener una conversaci칩n hablada con el modelo DeepSeek corriendo localmente en un sistema Debian. Utiliza Ollama para la inferencia y la API gratuita de Kokoro TTS para la s칤ntesis de voz.

### Caracter칤sticas

- **Conversaci칩n Interactiva:** Mantiene un historial de conversaci칩n para un contexto m치s coherente.
- **Modelo DeepSeek:** Usa el modelo `huihui_ai/deepseek-r1-abliterated:latest` de Ollama (un modelo sin censura, ideal para roleo y NSFW, permite configurar el prompt del sistema).
- **S칤ntesis de Voz:** Convierte las respuestas de DeepSeek a audio usando la API de Kokoro TTS.
- **Par치metros Optimizados:** Configuraci칩n predeterminada para una respuesta r치pida.
- **F치cil de Usar:** Interfaz simple de l칤nea de comandos.
- **Sanitizaci칩n de Texto:** Elimina los bloques `<think>` de las respuestas del modelo para una salida m치s limpia.

### Requisitos Previos

- **Ollama:** [Ollama](https://ollama.com/) instalado y configurado. Descarga el modelo DeepSeek: `ollama pull huihui_ai/deepseek-r1-abliterated:latest`.
- **jq:** `sudo apt install jq`
- **mpg123:** `sudo apt install mpg123`
- **Acceso a la API de Kokoro TTS:** El script usa la API gratuita (no se necesita clave API, pero ten en cuenta las limitaciones de uso).
- **Servidor Ollama Accesible:** El script necesita la URL de tu servidor Ollama. Si lo ejecutas localmente, puedes usar `http://localhost:11434/api/chat`. Si usas un servicio como Ngrok para exponerlo externamente, debes reemplazar la URL de ejemplo (`https://tu-direccion-ngrok-free.app/api/chat`) con la URL correcta.

### Configuraci칩n

Antes de ejecutar, revisa y ajusta estas variables en el script:

- **`MODEL`**: El modelo de Ollama a usar (por defecto: `huihui_ai/deepseek-r1-abliterated:latest`).
- **`MAX_CONTEXT`**: Tama침o del historial de conversaci칩n (por defecto: 6 turnos).
- **`SYSTEM_PROMPT`**: El prompt del sistema que gu칤a el comportamiento del modelo (personal칤zalo a tu gusto).
- **`TTS_API_URL`**: URL de la API de Kokoro TTS (no deber칤as necesitar cambiarla).
- **`VOICE`**: Voz de Kokoro TTS (consulta la documentaci칩n para las opciones disponibles).
- **`OLLAMA_PARAMS`**: Par치metros de generaci칩n de texto para Ollama (los predeterminados est치n optimizados para velocidad).
- **`API_ENDPOINT`**: **La URL de tu servidor Ollama.** Cambia `https://tu-direccion-ngrok-free.app/api/chat` por la direcci칩n correcta (e.g., `http://localhost:11434/api/chat` para local).

### C칩mo Ejecutar

1. **Guarda el script:** Guarda el c칩digo como `deepseek_tts_chat.sh`.
2. **Hazlo ejecutable:** `chmod +x deepseek_tts_chat.sh`
3. **Ejecuta el script:** `./deepseek_tts_chat.sh`
4. **Interact칰a:** Escribe tus preguntas despu칠s de "User 游땙: ".
5. **Salir:** Escribe `salir` para terminar.

### Notas Importantes

- **Servidor Ollama:** Aseg칰rate de que est칠 en ejecuci칩n y accesible en la direcci칩n configurada.
- **Conexi칩n a Internet:** Necesaria para comunicarse con Ollama (si no es local) y la API de TTS.
- **Limitaciones de la API TTS:** La API gratuita de Kokoro TTS puede tener restricciones de uso.
- **Latencia:** La velocidad depende de tu conexi칩n, la carga del servidor y la complejidad de la pregunta.

## 2. Ollama_Ngrok_Colab.ipynb: Ejecuta Ollama (y DeepSeek) en Google Colab con Acceso Remoto

Este cuaderno te permite instalar y ejecutar Ollama en Google Colab y hacerlo accesible desde cualquier lugar a trav칠s de un t칰nel seguro de Ngrok. Esto facilita el uso de modelos como DeepSeek desde fuera del entorno de Colab.

### Prerrequisitos

- **Cuenta de Ngrok y Token de Autenticaci칩n:** Reg칤strate en [Ngrok](https://ngrok.com/) y obt칠n tu token desde el panel de control.
- **Token de Ngrok en Google Colab Secrets:**
  1. En Colab, ve a "Secretos" (icono de llave en la barra lateral izquierda).
  2. Haz clic en "+ Secreto".
  3. Nombre: `NGROK_AUT_TOKEN`
  4. Valor: Pega tu token de Ngrok.
  5. Guarda.

### Instrucciones de Uso

1. **Abre el cuaderno en Google Colab.**
2. **Ejecuta las celdas en orden:** Cada celda est치 comentada para explicar su funci칩n.
   - **Instalaci칩n de Ollama.**
   - **Obtenci칩n del Token de Ngrok** (desde los secretos de Colab).
   - **Instalaci칩n de Paquetes:** `aiohttp` y `pyngrok`.
   - **Configuraci칩n de `LD_LIBRARY_PATH`** (para compatibilidad con drivers de NVIDIA).
   - **Funci칩n `run`** (para ejecutar comandos as칤ncronamente).
   - **Autenticaci칩n de Ngrok.**
   - **Ejecuci칩n de Ollama y Ngrok Concurrentemente:**
     - `ollama serve`: Inicia el servidor Ollama.
     - `ngrok http ...`: Crea el t칰nel seguro.
       - **URL Est치tica (Recomendado):** Usa la l칤nea con `--domain` y reemplaza `reemplazacontudomainde.ngrok-free.app` por tu subdominio deseado (e.g., `mi-ollama.ngrok-free.app`). Los dominios gratuitos terminan en `.ngrok-free.app`.
       - **URL Aleatoria (Alternativa):** Si prefieres una URL aleatoria cada vez, usa la l칤nea comentada sin `--domain`.
3. **Espera a que las celdas terminen.** La 칰ltima celda imprimir치 la URL de Ngrok (e.g., `url=https://tu-dominio.ngrok-free.app`).
4. **Accede a la API de Ollama:** Usa la URL de Ngrok para enviar peticiones a la API desde cualquier lugar. Ejemplo en Python:

```python
from ollama import Client

base_url = 'https://tu-dominio.ngrok-free.app'  # Reemplaza con tu URL
client = Client(host=base_url)

response = client.chat(model='llama2', messages=[{'role': 'user', 'content': '쮺apital de Francia?'}])
print(response['message']['content'])
```

### Consideraciones Importantes

- **Para Ejecutar en tu linux local:** export OLLAMA_HOST=<paste_url_here>.
- **URL de Ngrok:** Con dominio est치tico, la URL es la misma mientras tu cuenta est칠 activa. Sin dominio est치tico, cambia en cada ejecuci칩n.
- **Tiempo de Ejecuci칩n de Colab:** Colab tiene l칤mites de tiempo. Si se cierra, debes volver a ejecutar las celdas.
- **Seguridad:** Est치s exponiendo la API de Ollama a internet. Tenlo en cuenta si manejas datos sensibles.
- **Costos de Ngrok:** El plan gratuito es suficiente para pruebas. Para mayor ancho de banda o funciones avanzadas, revisa los planes de pago.
- **Modelos de Ollama:** Despu칠s de ejecutar el cuaderno, descarga los modelos que quieras usar (e.g., `!ollama pull llama2` en una nueva celda).

## 춰Disfruta experimentando con DeepSeek de forma local y remota!
